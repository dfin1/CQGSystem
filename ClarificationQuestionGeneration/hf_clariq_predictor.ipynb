{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OfDqwNP23u_"
   },
   "source": [
    "# Generate clarifying questions based on a Huggingface-BART Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources:\n",
    "The following implementation was build with orientation of the Bart Model used in those tutorials: <br>\n",
    "https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1 <br>\n",
    "https://towardsdatascience.com/teaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3fDnjiDoeZbK"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import argparse\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init the Pytorch lightning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "  # Instantiate the model\n",
    "  def __init__(self, learning_rate, tokenizer, model, hparams):\n",
    "    super().__init__()\n",
    "    self.tokenizer = tokenizer\n",
    "    self.model = model\n",
    "    self.learning_rate = learning_rate\n",
    "    # self.freeze_encoder = freeze_encoder\n",
    "    # self.freeze_embeds_ = freeze_embeds\n",
    "    self.save_hyperparameters(hparams)\n",
    "\n",
    "    if self.hparams.freeze_encoder:\n",
    "      freeze_params(self.model.get_encoder())\n",
    "\n",
    "    if self.hparams.freeze_embeds:\n",
    "      self.freeze_embeds()\n",
    "  \n",
    "  def freeze_embeds(self):\n",
    "    ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n",
    "    freeze_params(self.model.model.shared)\n",
    "    for d in [self.model.model.encoder, self.model.model.decoder]:\n",
    "      freeze_params(d.embed_positions)\n",
    "      freeze_params(d.embed_tokens)\n",
    "\n",
    "  # Do a forward pass through the model\n",
    "  def forward(self, input_ids, **kwargs):\n",
    "    return self.model(input_ids, **kwargs)\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    # Load the data into variables\n",
    "    src_ids, src_mask = batch[0], batch[1]\n",
    "    tgt_ids = batch[2]\n",
    "    # Shift the decoder tokens right (but NOT the tgt_ids)\n",
    "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
    "\n",
    "    # Run the model and get the logits\n",
    "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
    "    lm_logits = outputs[0]\n",
    "    # Create the loss function\n",
    "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "    # Calculate the loss on the un-shifted tokens\n",
    "    loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
    "\n",
    "    return {'loss':loss}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "\n",
    "    src_ids, src_mask = batch[0], batch[1]\n",
    "    tgt_ids = batch[2]\n",
    "\n",
    "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Run the model and get the logits\n",
    "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
    "    lm_logits = outputs[0]\n",
    "\n",
    "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "    val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
    "\n",
    "    return {'loss': val_loss}\n",
    "  \n",
    "  # Method that generates text using the BartForConditionalGeneration's generate() method\n",
    "  def generate_text(self, text, eval_beams, early_stopping = True, max_len = 40):\n",
    "    ''' Function to generate text '''\n",
    "    generated_ids = self.model.generate(\n",
    "        text[\"input_ids\"],\n",
    "        attention_mask=text[\"attention_mask\"],\n",
    "        use_cache=True,\n",
    "        decoder_start_token_id = self.tokenizer.pad_token_id,\n",
    "        num_beams= eval_beams,\n",
    "        max_length = max_len,\n",
    "        early_stopping = early_stopping\n",
    "    )\n",
    "    return [self.tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in generated_ids]\n",
    "\n",
    "def freeze_params(model):\n",
    "  ''' Function that takes a model as input (or part of a model) and freezes the layers for faster training\n",
    "      adapted from finetune.py '''\n",
    "  for layer in model.parameters():\n",
    "    layer.requires_grade = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hparams dictionary to pass in the model\n",
    "# I realise that this isn't really how this is meant to be used, but having this here reminds me that I can edit it when I need\n",
    "hparams = argparse.Namespace()\n",
    "\n",
    "hparams.freeze_encoder = True\n",
    "hparams.freeze_embeds = True\n",
    "hparams.eval_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BartConfig\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base', add_prefix_space=True)\n",
    "\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = LitModel.load_from_checkpoint(base_dir + \"../Models/hf_v2_6_Model.ckpt\", learning_rate = 2e-5, tokenizer = tokenizer, model = bart_model, hparams = hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting BART to predict some questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction(seed_line, model_):\n",
    "  # Put the model on eval mode\n",
    "  model_.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "  model_.eval()\n",
    "  \n",
    "  prompt_line_tokens = tokenizer(seed_line, max_length = 192, return_tensors = \"pt\", truncation = True)\n",
    "\n",
    "  line = model_.generate_text(prompt_line_tokens, eval_beams = 8)\n",
    "\n",
    "  return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung | Stockmarket, CEO, Devices, Headquarter\n",
      "[' What would you like to know about Samsung?']\n"
     ]
    }
   ],
   "source": [
    "seed_line = \"Samsung | Stockmarket, CEO, Devices, Headquarter\"\n",
    "line_pred = generate_prediction(seed_line = seed_line, model_ = model_loaded)\n",
    "\n",
    "print(seed_line)\n",
    "print(line_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung | Television , Smartphone, Soundbox , Computer , Vaccum\n",
      "[' Which \"Samsung\" do you mean?']\n"
     ]
    }
   ],
   "source": [
    "seed_line = \"Samsung | Television , Smartphone, Soundbox , Computer , Vaccum\"\n",
    "line_pred = generate_prediction(seed_line = seed_line, model_ = model_loaded)\n",
    "\n",
    "print(seed_line)\n",
    "print(line_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mercedes cla class convertible | exterior , interior , engine , prices , competition\n",
      "[' What do you want to know about this vehicle?']\n"
     ]
    }
   ],
   "source": [
    "seed_line = \"mercedes cla class convertible | exterior , interior , engine , prices , competition\"\n",
    "line_pred = generate_prediction(seed_line = seed_line, model_ = model_loaded)\n",
    "\n",
    "print(seed_line)\n",
    "print(line_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selena Gomez | Age , Birthday , Albums , Livingplace\n",
      "[' What do you want to know about the singer?']\n"
     ]
    }
   ],
   "source": [
    "seed_line = \"Selena Gomez | Age , Birthday , Albums , Livingplace\"\n",
    "line_pred = generate_prediction(seed_line = seed_line, model_ = model_loaded)\n",
    "\n",
    "print(seed_line)\n",
    "print(line_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Testdataset\n",
    "And calculate some metrices for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loadings Dataset\n",
    "df = pd.read_csv(base_dir + '../Data/Dataset_v2_6_20f_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['predicted', 'Blue', 'Blue_1gram', 'Blue_2gram', 'Blue_3gram']] = ''\n",
    "\n",
    "df[['rouge_1_r', 'rouge_1_p', 'rouge_1_f', 'rouge_2_r',\n",
    "    'rouge_2_p', 'rouge_2_f', 'rouge_l_r', 'rouge_l_p' ,'rouge_l_f']] = ''\n",
    "\n",
    "df[['bert_p', 'bert_r', 'bert_f1']] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dfingerlos\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\dfingerlos\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\dfingerlos\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1801.9053971767426 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    #rnd = random.randint(0,len(df))\n",
    "    line = df.iloc[i]['source']\n",
    "    question_pred = generate_prediction(seed_line = line, model_ = model_loaded)\n",
    "    question_true = df.iloc[i]['target']\n",
    "    \n",
    "    Blue_score = sentence_bleu([question_pred[0].split()], question_true.split())\n",
    "    Blue_score_1n = sentence_bleu([question_pred[0].split()], question_true.split(), weights=(1, 0, 0, 0))\n",
    "    Blue_score_2n = sentence_bleu([question_pred[0].split()], question_true.split(), weights=(0, 1, 0, 0))\n",
    "    Blue_score_3n = sentence_bleu([question_pred[0].split()], question_true.split(), weights=(0, 0, 1, 0))\n",
    "        \n",
    "    rouge = Rouge()\n",
    "    rouge_res = rouge.get_scores(question_pred[0], question_true)\n",
    "\n",
    "    df.loc[i]['predicted'] = question_pred\n",
    "    df.loc[i]['Blue'] = Blue_score\n",
    "    df.loc[i]['Blue_1gram'] = Blue_score_1n\n",
    "    df.loc[i]['Blue_2gram'] = Blue_score_2n\n",
    "    df.loc[i]['Blue_3gram'] = Blue_score_3n\n",
    "\n",
    "    df.loc[i]['rouge_1_r'] = rouge_res[0][\"rouge-1\"]['r']\n",
    "    df.loc[i]['rouge_1_p'] = rouge_res[0][\"rouge-1\"]['p']\n",
    "    df.loc[i]['rouge_1_f'] = rouge_res[0][\"rouge-1\"]['f']\n",
    "    df.loc[i]['rouge_2_r'] = rouge_res[0][\"rouge-2\"]['r']\n",
    "    df.loc[i]['rouge_2_p'] = rouge_res[0][\"rouge-2\"]['p']\n",
    "    df.loc[i]['rouge_2_f'] = rouge_res[0][\"rouge-2\"]['f']\n",
    "    df.loc[i]['rouge_l_r'] = rouge_res[0][\"rouge-l\"]['r']\n",
    "    df.loc[i]['rouge_l_p'] = rouge_res[0][\"rouge-l\"]['p']\n",
    "    df.loc[i]['rouge_l_f'] = rouge_res[0][\"rouge-l\"]['f']\n",
    "\n",
    "        \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5980e9288c164af2b97a3cdf62024488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4907e9c560f14133af8224ee7bae307d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 87.96 seconds, 21.67 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "P, R, F1 = score(df['target'].values.tolist(), df['predicted'].values.tolist(), lang=\"en\", verbose=True)\n",
    "\n",
    "df['bert_p'] = P\n",
    "df['bert_r'] = R\n",
    "df['bert_f1'] = F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/hf_v2_6_evalResults_20f.csv\", sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hf_starter_v0.5_trainer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09ab2772c5cd46cbad182046cfa164ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "0a220878210c4b449491091cc6121dd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a380fc2053fa4d43a2a3548aad1c1d1e",
      "placeholder": "​",
      "style": "IPY_MODEL_955511cd4c9b4b92b20843d1caeff908",
      "value": "Sanity Checking DataLoader 0: 100%"
     }
    },
    "1a6e2c8da0084871b1ef043e43481246": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "4f87e81080a24e7cb6d086ada1e6d4c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52bbc15f7eae43e58f80090087ea5b1c",
      "placeholder": "​",
      "style": "IPY_MODEL_690e60aa1bfb4d5bac05e68a44af99f0",
      "value": " 2/2 [00:20&lt;00:00, 10.03s/it]"
     }
    },
    "52bbc15f7eae43e58f80090087ea5b1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5aef1d474e754cc6812e3c3f90bcc601": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "690e60aa1bfb4d5bac05e68a44af99f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72f2a3066c8e44ca8981ff67316fda88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ef5c7e16557454d83e61c7201fe1ecd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "906082500f2b48d6918c4d8cf4424e4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "955511cd4c9b4b92b20843d1caeff908": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96ec323ba8674a4aa417f23d784dcc1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f11f45195d1048afb42a270f7e6249c5",
       "IPY_MODEL_c6e6d42120a448f0992407869fb30a4a",
       "IPY_MODEL_deab8aee5d434d33947e88e105756683"
      ],
      "layout": "IPY_MODEL_1a6e2c8da0084871b1ef043e43481246"
     }
    },
    "a37a6e1ed2b549cfbc9090855a00c043": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72f2a3066c8e44ca8981ff67316fda88",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fb0e30f4900947ec82dbe89682e2af7a",
      "value": 1
     }
    },
    "a380fc2053fa4d43a2a3548aad1c1d1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4c3eb758a924db8b6f67a37029dee0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7e869274faf45df99e4ecf2c728fa58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2efc778a59b4b54b03dea3daab6a06d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6e6d42120a448f0992407869fb30a4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7e869274faf45df99e4ecf2c728fa58",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_906082500f2b48d6918c4d8cf4424e4f",
      "value": 0
     }
    },
    "deab8aee5d434d33947e88e105756683": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ef5c7e16557454d83e61c7201fe1ecd",
      "placeholder": "​",
      "style": "IPY_MODEL_5aef1d474e754cc6812e3c3f90bcc601",
      "value": " 0/242 [00:00&lt;?, ?it/s]"
     }
    },
    "f11f45195d1048afb42a270f7e6249c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2efc778a59b4b54b03dea3daab6a06d",
      "placeholder": "​",
      "style": "IPY_MODEL_a4c3eb758a924db8b6f67a37029dee0c",
      "value": "Epoch 0:   0%"
     }
    },
    "f1a9bba5ee9a464baf7b9d7db8474efb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a220878210c4b449491091cc6121dd0",
       "IPY_MODEL_a37a6e1ed2b549cfbc9090855a00c043",
       "IPY_MODEL_4f87e81080a24e7cb6d086ada1e6d4c9"
      ],
      "layout": "IPY_MODEL_09ab2772c5cd46cbad182046cfa164ac"
     }
    },
    "fb0e30f4900947ec82dbe89682e2af7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
